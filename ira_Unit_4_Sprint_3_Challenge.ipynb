{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ira_Unit_4_Sprint_3_Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "name": "u4-s3-dnn",
      "language": "python",
      "display_name": "U4-S3-DNN (Python 3.7)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragmatizt/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/ira_Unit_4_Sprint_3_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne5SUADtA9K1",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on SageMaker, Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe the components of an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - RNNs\n",
        "\n",
        "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "outputId": "95ead12f-9d2a-459d-dda1-7e2ab89a5fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi2yBFp2B2aD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3e6957f-8e6e-4109-dd49-5e884014e8f0"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982,), (8982,), (2246,), (2246,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "6462a4e5-6373-47aa-fa19-9d16e1898be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "43d5e202-3b31-45f2-89fe-ae82e39f1572"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "\n",
        "batch_size = 46\n",
        "max_features = len(word_index.values())\n",
        "maxlen = 200\n",
        "\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.1, recurrent_dropout=0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8982 train sequences\n",
            "2246 test sequences\n",
            "Pad sequences (samples x time)\n",
            "X_train shape: (8982, 200)\n",
            "X_test shape: (2246, 200)\n",
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR68S6v1A9Lq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6fc9bfe0-f75b-4216-cca7-b326d078d633"
      },
      "source": [
        "# You should only run this cell once your model has been properly configured\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='nadam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score, acc = model.evaluate(X_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 8982 samples, validate on 2246 samples\n",
            "8982/8982 [==============================] - 67s 7ms/sample - loss: nan - acc: 0.0470 - val_loss: nan - val_acc: 0.0374\n",
            "2246/2246 [==============================] - 3s 1ms/sample - loss: nan - acc: 0.0387\n",
            "Test score: nan\n",
            "Test accuracy: 0.03873553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GjTAvJmDj48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16178261-58f9-4122-cde2-2faa427ac155"
      },
      "source": [
        "# Reference for the Sequence Data Question below:\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982, 200), (2246, 200))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxApIf33A9L0",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "\n",
        "**Answer**: Pad sequences transforms a list into a 2D numpy array.  As we can see in the first time we split the data, it was 1 dimensional.\n",
        "\n",
        "To transform it into a 2D array, we used the the pad_sequences() method. Also, the maxlen indicates the maximum length of each sequence.\n",
        "\n",
        "So as we transform these into 2D arrays, we ensure that they are the same shape by using the maxlen parameter.\n",
        "\n",
        "**References** (for my future self reviewing this sprint challenge): \n",
        "- [Keras Documentation](https://keras.io/preprocessing/sequence/)\n",
        "- [Stack Overflow](https://stackoverflow.com/questions/42943291/what-does-keras-io-preprocessing-sequence-pad-sequences-do)\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "\n",
        "**Answer**: Simply put, LSTM's can remember information for long periods of time.  \n",
        "\n",
        "In non-technical terms it can bring up \"context\" from the past to present & future information.  \n",
        "\n",
        "LSTM's have the ability to add or remove information to the cell state by structures called **gates**.\n",
        "\n",
        "*\"Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.\"* - Blog post referenced below.\n",
        "\n",
        "![alt text](https://i.stack.imgur.com/Iv3nU.png)\n",
        "\n",
        "**Reference Links**:\n",
        "- [StackOverflow](https://i.stack.imgur.com/Iv3nU.png)\n",
        "- [Blog Post on LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "- [Link](https://arxiv.org/ftp/arxiv/papers/1604/1604.04573.pdf): Saw on my google searches; looked like an interesting article on multi-label image classification\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
        "\n",
        "**Answer**: \n",
        "- Unsegmented, connected handwriting recognition \n",
        "- Speech recognition\n",
        "- Anomaly detection in network traffic\n",
        "\n",
        "They're best suited for the cases mentioned above because LSTM excels in classifying, processing, and making predictions on *time series* data.\n",
        "\n",
        "In each of the cases above, there could be an unspecified period of time between events.  \n",
        "\n",
        "The fact that LSTM \"remembers\" makes it an excellent tool for these sort of problems.  \n",
        "\n",
        "**Reference Link**:\n",
        "- [Wikipedia](https://en.wikipedia.org/wiki/Long_short-term_memory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "4c22cc22-84f7-44fd-9f52-688fe5637bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google_images_download in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (from google_images_download) (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "c4eee7c6-5000-4da3-c40f-3c4ef9178eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"lilly frog pond\", \"limit\": 5, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)\n",
        "\n",
        "# One error below.  Looks like the fifth image is returning a 404 error."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = lilly frog pond\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: http://www.slrobertson.com/images/usa/georgia/atlanta/atl-botanical-gardens/frog-lily-pond-2-b.jpg\n",
            "Completed Image ====> 1.frog-lily-pond-2-b.jpg\n",
            "Image URL: https://cdn.pixabay.com/photo/2017/07/14/17/44/frog-2504507_960_720.jpg\n",
            "Completed Image ====> 2.frog-2504507_960_720.jpg\n",
            "Image URL: https://storage.needpix.com/rsynced_images/bull-frog-2526024_1280.jpg\n",
            "Completed Image ====> 3.bull-frog-2526024_1280.jpg\n",
            "Image URL: https://i.pinimg.com/originals/9a/49/08/9a49083d4d7458a194a451eea757a444.jpg\n",
            "Completed Image ====> 4.9a49083d4d7458a194a451eea757a444.jpg\n",
            "Image URL: https://www.maxpixel.net/static/photo/1x/Frog-Pond-Lily-Pad-Water-Nature-Animal-4336943.jpg\n",
            "URLError on an image...trying next one... Error: HTTP Error 404: Page not found\n",
            "Image URL: https://image.shutterstock.com/image-photo/green-frogs-pond-lilly-pads-260nw-50197960.jpg\n",
            "Completed Image ====> 5.green-frogs-pond-lilly-pads-260nw-50197960.jpg\n",
            "\n",
            "Errors: 1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goals* \n",
        "- Check for fish or other labels\n",
        "- Create a matplotlib visualizations of the images and your prediction as the visualization label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoDod5tkaLgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "4f765abf-4155-469a-b0e8-3f6e26513188"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    model = ResNet50(weights='imagenet')\n",
        "    features = model.predict(x)\n",
        "    frog_results = decode_predictions(features, top=3)[0]\n",
        "    print(frog_results)\n",
        "    frog_results.append\n",
        "    for entry in frog_results:\n",
        "        if 'frog'in entry[1]:\n",
        "            return True\n",
        "    # Else:\n",
        "    return False \n",
        "\n",
        "def img_contains_fish(img):\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    model = ResNet50(weights='imagenet')\n",
        "    features = model.predict(x)\n",
        "    fish_results = decode_predictions(features, top=3)[0]\n",
        "    fish_results.append(decode_predictions(features, top=10)[0])\n",
        "    print(fish_results)\n",
        "    fish_results.append\n",
        "    for entry in fish_results:\n",
        "        if 'fish'in entry[1]:\n",
        "            return True\n",
        "    #Else:\n",
        "    return False\n",
        "\n",
        "\n",
        "# Frogs\n",
        "for x in absolute_image_paths[0]['lilly frog pond']:\n",
        "    x = process_img_path(x)\n",
        "    print(img_contains_frog(x))\n",
        "    \n",
        "# Fish\n",
        "for x in absolute_image_paths[0]['lilly frog pond']:\n",
        "    x = process_img_path(x)\n",
        "    print(img_contains_fish(x))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('n03991062', 'pot', 0.7243723), ('n01641577', 'bullfrog', 0.045519695), ('n01667778', 'terrapin', 0.04263503)]\n",
            "True\n",
            "[('n01641577', 'bullfrog', 0.35860497), ('n01644900', 'tailed_frog', 0.30636418), ('n01737021', 'water_snake', 0.15603636)]\n",
            "True\n",
            "[('n01644373', 'tree_frog', 0.7534928), ('n01641577', 'bullfrog', 0.13603099), ('n01644900', 'tailed_frog', 0.10173123)]\n",
            "True\n",
            "[('n04476259', 'tray', 0.6419137), ('n03485794', 'handkerchief', 0.18807994), ('n01644373', 'tree_frog', 0.01435911)]\n",
            "True\n",
            "[('n03991062', 'pot', 0.3353414), ('n04522168', 'vase', 0.13951766), ('n02280649', 'cabbage_butterfly', 0.08299894)]\n",
            "False\n",
            "[('n03991062', 'pot', 0.7243723), ('n01641577', 'bullfrog', 0.045519695), ('n01667778', 'terrapin', 0.04263503), [('n03991062', 'pot', 0.7243723), ('n01641577', 'bullfrog', 0.045519695), ('n01667778', 'terrapin', 0.04263503), ('n02877765', 'bottlecap', 0.0326819), ('n01737021', 'water_snake', 0.020111015), ('n04409515', 'tennis_ball', 0.018943807), ('n07753113', 'fig', 0.016971406), ('n12620546', 'hip', 0.012854), ('n01667114', 'mud_turtle', 0.011956065), ('n04326547', 'stone_wall', 0.005900005)]]\n",
            "False\n",
            "[('n01641577', 'bullfrog', 0.35860497), ('n01644900', 'tailed_frog', 0.30636418), ('n01737021', 'water_snake', 0.15603636), [('n01641577', 'bullfrog', 0.35860497), ('n01644900', 'tailed_frog', 0.30636418), ('n01737021', 'water_snake', 0.15603636), ('n01644373', 'tree_frog', 0.07753513), ('n01667778', 'terrapin', 0.066418745), ('n01698640', 'American_alligator', 0.00985023), ('n01667114', 'mud_turtle', 0.0041945684), ('n02011460', 'bittern', 0.0015473735), ('n01697457', 'African_crocodile', 0.001492388), ('n01669191', 'box_turtle', 0.0012751498)]]\n",
            "False\n",
            "[('n01644373', 'tree_frog', 0.7534928), ('n01641577', 'bullfrog', 0.13603099), ('n01644900', 'tailed_frog', 0.10173123), [('n01644373', 'tree_frog', 0.7534928), ('n01641577', 'bullfrog', 0.13603099), ('n01644900', 'tailed_frog', 0.10173123), ('n01693334', 'green_lizard', 0.002121371), ('n01682714', 'American_chameleon', 0.0011545183), ('n01667114', 'mud_turtle', 0.00072577735), ('n01667778', 'terrapin', 0.0006487901), ('n07716358', 'zucchini', 0.00061014405), ('n01694178', 'African_chameleon', 0.00029618407), ('n12267677', 'acorn', 0.00019486902)]]\n",
            "False\n",
            "[('n04476259', 'tray', 0.6419137), ('n03485794', 'handkerchief', 0.18807994), ('n01644373', 'tree_frog', 0.01435911), [('n04476259', 'tray', 0.6419137), ('n03485794', 'handkerchief', 0.18807994), ('n01644373', 'tree_frog', 0.01435911), ('n02281406', 'sulphur_butterfly', 0.010928565), ('n03598930', 'jigsaw_puzzle', 0.010002702), ('n09256479', 'coral_reef', 0.009199111), ('n02834397', 'bib', 0.008844615), ('n03938244', 'pillow', 0.00832463), ('n02808304', 'bath_towel', 0.007111974), ('n06596364', 'comic_book', 0.0066061257)]]\n",
            "False\n",
            "[('n03991062', 'pot', 0.3353414), ('n04522168', 'vase', 0.13951766), ('n02280649', 'cabbage_butterfly', 0.08299894), [('n03991062', 'pot', 0.3353414), ('n04522168', 'vase', 0.13951766), ('n02280649', 'cabbage_butterfly', 0.08299894), ('n02281787', 'lycaenid', 0.033327255), ('n02206856', 'bee', 0.032424893), ('n11939491', 'daisy', 0.026388831), ('n03000134', 'chainlink_fence', 0.019126037), ('n03930313', 'picket_fence', 0.018211326), ('n07745940', 'strawberry', 0.013631654), ('n12620546', 'hip', 0.013529578)]]\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oErE_CirA9Mk",
        "colab_type": "text"
      },
      "source": [
        "#### Stretch Goal: Displaying Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVDO-mn1ffBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Couldn't get code to work.  Good \"code challenge\" for myself once Winter Break starts."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "*Answer:* Given that it tries to predict its own input, one novel way of using autoencoders is image denoising.  Oftentimes images contain noise in the data -- autoencoders can get rid of that noise!\n",
        "\n",
        "- [Medium](https://medium.com/datadriveninvestor/deep-learning-autoencoders-db265359943e), a decent blog post overview on autoencoders.\n",
        "- [Kaggle](https://www.kaggle.com/shivamb/how-autoencoders-work-intro-and-usecases), I love this Kaggle post on AutoEncoders.  Putting this on my list for winter reading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- **What do you consider your strongest area, as a Data Scientist?**\n",
        "\n",
        "**Answer**: I would actually consider my non-technical experience as something that will help me in the long term.  \n",
        "\n",
        "I have a background in sales, operations, and entrepreneurship.  So I'm comfortable with *storytelling* (selling a product or service), I understand business (which will help me share the data with different stakeholders: whether C-suite, finance, marketing, or customers, etc.), and I have an undergrad background in Economics (a general understanding of data and visualizations which can help me tell the story).\n",
        "\n",
        "- **What area of Data Science would you most like to learn more about, and why?**\n",
        "\n",
        "**Answer**: You know, I was more inspired by the data anlytics and visualizations part of Data Science, but since starting Unit 4, and learning about all the cool things that we can do with images, text, ... anything(!), I kind of want to spend some time looking into this deeper.\n",
        "\n",
        "But I would be happy if my starting job in this field is as a Data Analyst or as a Business Intelligence analyst (plays on the strengths I mentioned above)\n",
        "\n",
        "- **Where do you think Data Science will be in 5 years?**\n",
        "\n",
        "**Answer**: Able to process more data (5G, stronger hardware), maybe one or two groundbreaking algorithms, more ubiquitous, more unintimidating to the general population.\n",
        "\n",
        "Fully integrated with industries like energy, agriculture, finance, tech (of course), practically every industry will see the value in Data Science.\n",
        "\n",
        "- **What are the threats posed by AI to our society?**\n",
        "\n",
        "**Answer**: The social and economic changes are the biggest and most obvious ones.  There will be a massive job displacement for people all over the world.  Like every technological revolution in the past: agricultural, industrial, digital.  \n",
        "\n",
        "- **How do you think we can counteract those threats? **\n",
        "\n",
        "**Answer**: We need to have our brightest minds look into how to best \"catch\" these massive amounts of people that will see their jobs become obsolete due to A.I.\n",
        "\n",
        "To have support structures that will allow them to reskill.  Whether that's financial support during the time that they're reskilling, as well as the educational support that allows them to get the best education while reskilling.\n",
        "\n",
        "(Lambda is doing a great job as a solution to this, which is already happening)\n",
        "\n",
        "- **Do you think achieving General Artifical Intelligence is ever possible?**\n",
        "\n",
        "**Answer**: Yes, I do.  As hardware, algorithms, and internet speeds (meaning improved pipelines) improves, I think it's only a matter of time.\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoN2ZF2eA9NB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "2c6b4ea5-459f-44ec-a881-56350659c389"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUsou3rtadp5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0e0c0c3-71b9-4ade-da23-71cc78276b81"
      },
      "source": [
        "print(\"Woohoo!  We did it.  Survived four units of Lambda School.  Onto labs!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Woohoo!  We did it.  Survived four units of Lambda School.  Onto labs!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}